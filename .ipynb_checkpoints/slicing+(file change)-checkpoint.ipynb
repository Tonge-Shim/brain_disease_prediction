{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "from operator import add\n",
    "import matplotlib.pyplot as plt\n",
    "import easydict\n",
    "import dicom2nifti\n",
    "import dicom2nifti.settings as settings\n",
    "settings.disable_validate_slice_increment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mra--> nii file 변환작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcm_path = '/home/chaeeun/MRI100_NECKTOFMRA/*'\n",
    "# nii_path = '/home/chaeeun/Desktop/brain disease prediction/fileIO/data_niis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcm_list_path = '/home/chaeeun/Necktofmra'\n",
    "# dcm_list =  os.listdir(dcm_list_path)\n",
    "# dcm_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dcm --> nii code\n",
    "# #for i, patient in enumerate(glob(dcm_path)):nonononononono please don't use this line\n",
    "# for f in tqdm(dcm_list):\n",
    "#     dicom2nifti.dicom_series_to_nifti(dcm_list_path +'/'+ f, os.path.join(nii_path, f + '.nii.gz'))#nii_path에 파일 추가\n",
    "#     print(f + 'done')#well done check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 끝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, '10436442_20170329_095856_MR.nii.gz')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii_path = '/home/chaeeun/Desktop/brain disease prediction/fileIO/data_niis/'\n",
    "files = os.listdir(nii_path)\n",
    "files.sort()\n",
    "files = files[1:]#ipynb_checkpoints file name remove...\n",
    "len(files), files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resize (192, 252, 272 -> 232, z축)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(x, y, z):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resize done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 248/721 [03:53<07:24,  1.06it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2220400 into shape (1,140,130,162)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-745f02aa416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliced_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m162\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2220400 into shape (1,140,130,162)"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for f in tqdm(files):\n",
    "    path = os.path.join(nii_path, f)\n",
    "    img = nib.load(path)\n",
    "    sliced_img = img.slicer[190:330, 220:350, 70:232]\n",
    "    img = sliced_img.get_fdata()\n",
    "    img = np.asarray(np.float32(img))\n",
    "    img = img.reshape(1, 140, 130, 162)\n",
    "    data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_to_232(files, origin_path, new_path):\n",
    "    for f in tqdm(files):\n",
    "        path = os.path.join(origin_path, f)\n",
    "        img = nib.load(path)\n",
    "        if img.shape[2] == 192:\n",
    "            conformed_img = nibabel.processing.conform(img, out_shape=(512, 512, 232))\n",
    "            nib.save(conformed_img, os.path.join(newpath, f))\n",
    "            \n",
    "            \n",
    "        \n",
    "        elif img.shape[2] == 232:\n",
    "            nib.save(img, os.path.join(newpath, f))\n",
    "            \n",
    "        elif img.shape[2] == 233:\n",
    "            sliced_img = img.slicer[:, :, 1:]\n",
    "            nib.save(sliced_img, os.path.join(newpath, f))\n",
    "            \n",
    "        elif img.shape[2] == 252:\n",
    "            sliced_img = img.slicer[:, :, 20:]\n",
    "            nib.save(sliced_img, os.path.join(newpath, f))\n",
    "            \n",
    "        elif img.shape[2] == 272:\n",
    "            sliced_img = img.slicer[:, :, 40:]\n",
    "            nib.save(sliced_img, os.path.join(newpath, f))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = '/home/chaeeun/Desktop/brain disease prediction/fileIO/data_niis/'\n",
    "new_path = '/home/chaeeun/Desktop/brain disease prediction/fileIO/data_nii_232/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 170/721 [00:15<00:00, 840.00it/s]"
     ]
    }
   ],
   "source": [
    "for f in tqdm(files):\n",
    "    path = os.path.join(origin_path, f)\n",
    "    img = nib.load(path)\n",
    "    if img.shape[2] == 192:\n",
    "        img = img.get_fdata()\n",
    "        zoom_img = zoom(img, (1, 1, 232/192))\n",
    "        new_image = nib.Nifti1Image(zoom_img)\n",
    "        nib.save(new_img, os.path.join(new_path, f))\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{192, 232, 233, 272, 252}\n"
     ]
    }
   ],
   "source": [
    "s  = set()\n",
    "for i in files:\n",
    "    path = os.path.join(nii_path, i)\n",
    "    img = nib.load(path)\n",
    "    s.add(img.shape[2])\n",
    "print(s)\n",
    "# a = 0\n",
    "# for i in files:\n",
    "#     path = os.path.join(nii_path, i)\n",
    "#     img = nib.load(path)\n",
    "#     if img.shape[2] == 192:\n",
    "#         a += 1\n",
    "# print(a)#192짜리 개수 확인\n",
    "# path = os.path.join(nii_path, '37315317_20170927_090449_MR.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)\n",
    "data = np.array(data, dtype='float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 1, 170, 140, 172)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./sliced_datas/sliced_435', data, allow_pickle=True, fix_imports=True)\n",
    "# 0 : [190:330, 220:350, 70:220], 140 130 150\n",
    "# np.save('./sliced_datas/sliced_757', data, allow_pickle=True, fix_imports=True)\n",
    "# 1 : [180:350, 200:350, 60:232] 170 150 172메모리 아웃\n",
    "np.save('./sliced_datas/sliced_436', data, allow_pickle=True, fix_imports=True)\n",
    "# 0 : [190:330, 220:350, 70:232] 140 130 162\n",
    "# np.save('./sliced_datas/sliced_746', data, allow_pickle=True, fix_imports=True)\n",
    "# 0 : [170:340, 180:320, 70:232] 170 140 162\n",
    "# np.save('./sliced_datas/sliced_747', data, allow_pickle=True, fix_imports=True)\n",
    "# 0 : [170:340, 180:320, 60:232] 170 140 172\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bb3e46167f5c400af3e59bea929666d662dd7e99f9046bb04b64be6ff24130e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
